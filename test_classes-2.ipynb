{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Supervised Machine Learning (Classification)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_reader import ConfigReader\n",
    "from dataset import Dataset\n",
    "from data_predictor import DataPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three sklearn classifiers [_SVM_](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC) (Support Vector Classification), [_Logistic Regression Classifier_](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), and [_Dummy Classifier_](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html) are imported to the notebook and instantiated. You should try additional classifiers from [sklearn](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning) yourself.   \n",
    "**Don't forget** to import and add your own implementation of kNN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "support_vector_clf = svm.SVC(kernel=\"linear\") \n",
    "logistic_regression_clf = LogisticRegression(random_state=0, max_iter=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Disease Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the classifiers on the Heart Disease Dataset, by passing the created classifier objects to ``DataPredictor``'s ``best_classifier`` method (add your additional classifier objects to the list here). For comparison and visualization, the methods ``print_evaluation_results`` and ``visualize_classification_results`` are called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = ConfigReader.read_json_config(\"./config_heart_disease.json\")\n",
    "dataset = Dataset(config_dict)\n",
    "predictor = DataPredictor(dataset, config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": "(array([[37.,  0.,  2., ..., nan, nan, nan],\n        [49.,  1.,  4., ..., nan, nan, nan],\n        [45.,  0.,  2., ...,  2.,  0.,  3.],\n        ...,\n        [57.,  1.,  3., ...,  2., nan, nan],\n        [53.,  0.,  2., ...,  2., nan, nan],\n        [57.,  0.,  4., ...,  1.,  1.,  3.]]),\n array([0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,\n        0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.,\n        1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,\n        1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.,\n        1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n        0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n        0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1.,\n        1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1.,\n        0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n        0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1.,\n        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n        1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1.,\n        1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,\n        1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n        1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,\n        1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1.,\n        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,\n        1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n        1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n        1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0.,\n        0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n        1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n        0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,\n        1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n        1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,\n        0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n        0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,\n        0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,\n        1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n        1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1.,\n        1., 1., 0., 0.]),\n array([[36.,  1.,  2., ..., nan, nan, nan],\n        [45.,  1.,  2., ..., nan, nan, nan],\n        [48.,  1.,  4., ...,  2., nan, nan],\n        ...,\n        [43.,  1.,  4., ...,  1.,  0.,  3.],\n        [50.,  1.,  4., ..., nan, nan, nan],\n        [62.,  0.,  4., ...,  2.,  3.,  3.]]),\n array([0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,\n        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n        0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n        0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1.,\n        0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1.,\n        1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.,\n        1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,\n        0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0.,\n        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,\n        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1.,\n        1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n        0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0.,\n        0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0.,\n        1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n        1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0.,\n        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,\n        0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1.]))"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.split_data(impute_strategy='mean')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifier = predictor.best_classifier([dummy_clf, support_vector_clf, logistic_regression_clf])\n",
    "predictor.print_evaluation_results()\n",
    "predictor.visualize_classification_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parkinson Speech Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the Parkinson Speech Dataset, again the created classifier objects are passed to ``DataPredictor``'s ``best_classifier`` method (add your additional classifier objects to the list here). For comparison and visualization, the methods ``print_evaluation_results`` and ``visualize_classification_results`` are called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = ConfigReader.read_json_config(\"./config_parkinson_sound_recording.json\")\n",
    "dataset = Dataset(config_dict)\n",
    "predictor = DataPredictor(dataset, config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifier = predictor.best_classifier([dummy_clf, support_vector_clf, logistic_regression_clf])\n",
    "predictor.print_evaluation_results()\n",
    "predictor.visualize_classification_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}